{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = nn.Embedding(20, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.num_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz (37.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 37.4MB 56.3MB/s ta 0:00:011    82% |██████████████████████████▎     | 30.7MB 36.2MB/s eta 0:00:01\n",
      "\u001b[?25h  Requirement already satisfied (use --upgrade to upgrade): en-core-web-sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz in /Users/sob/Desktop/cs287/homeworks/env/lib/python3.6/site-packages\n",
      "\n",
      "\u001b[93m    Linking successful\u001b[0m\n",
      "    /Users/sob/Desktop/cs287/homeworks/env/lib/python3.6/site-packages/en_core_web_sm\n",
      "    -->\n",
      "    /Users/sob/Desktop/cs287/homeworks/env/lib/python3.6/site-packages/spacy/data/en\n",
      "\n",
      "    You can now load the model via spacy.load('en')\n",
      "\n",
      "Collecting https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.0.0/de_core_news_sm-2.0.0.tar.gz\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.0.0/de_core_news_sm-2.0.0.tar.gz (38.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 38.2MB 47.1MB/s ta 0:00:011 1% |▍                               | 440kB 7.3MB/s eta 0:00:06    96% |███████████████████████████████ | 37.1MB 49.8MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: de-core-news-sm\n",
      "  Running setup.py install for de-core-news-sm ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed de-core-news-sm-2.0.0\n",
      "\n",
      "\u001b[93m    Linking successful\u001b[0m\n",
      "    /Users/sob/Desktop/cs287/homeworks/env/lib/python3.6/site-packages/de_core_news_sm\n",
      "    -->\n",
      "    /Users/sob/Desktop/cs287/homeworks/env/lib/python3.6/site-packages/spacy/data/de\n",
      "\n",
      "    You can now load the model via spacy.load('de')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en\n",
    "!python -m spacy download de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in tokenizers for German and English\n",
    "spacy_de = spacy.load('de')\n",
    "spacy_en = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create utility functions to tokenize them\n",
    "def tokenize_de(text):\n",
    "    return [tok.text for tok in spacy_de.tokenizer(text)]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a beginning of sentence token and end of sentence token for target language only\n",
    "BOS_WORD = '<s>'\n",
    "EOS_WORD = '</s>'\n",
    "DE = data.Field(tokenize=tokenize_de)\n",
    "EN = data.Field(tokenize=tokenize_en, init_token = BOS_WORD, eos_token = EOS_WORD) # only target needs BOS/EOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading de-en.tgz\n",
      ".data/iwslt/de-en/IWSLT16.TED.dev2010.de-en.de.xml\n",
      ".data/iwslt/de-en/IWSLT16.TED.dev2010.de-en.en.xml\n",
      ".data/iwslt/de-en/IWSLT16.TED.tst2010.de-en.de.xml\n",
      ".data/iwslt/de-en/IWSLT16.TED.tst2010.de-en.en.xml\n",
      ".data/iwslt/de-en/IWSLT16.TED.tst2011.de-en.de.xml\n",
      ".data/iwslt/de-en/IWSLT16.TED.tst2011.de-en.en.xml\n",
      ".data/iwslt/de-en/IWSLT16.TED.tst2012.de-en.de.xml\n",
      ".data/iwslt/de-en/IWSLT16.TED.tst2012.de-en.en.xml\n",
      ".data/iwslt/de-en/IWSLT16.TED.tst2013.de-en.de.xml\n",
      ".data/iwslt/de-en/IWSLT16.TED.tst2013.de-en.en.xml\n",
      ".data/iwslt/de-en/IWSLT16.TED.tst2014.de-en.de.xml\n",
      ".data/iwslt/de-en/IWSLT16.TED.tst2014.de-en.en.xml\n",
      ".data/iwslt/de-en/IWSLT16.TEDX.dev2012.de-en.de.xml\n",
      ".data/iwslt/de-en/IWSLT16.TEDX.dev2012.de-en.en.xml\n",
      ".data/iwslt/de-en/IWSLT16.TEDX.tst2013.de-en.de.xml\n",
      ".data/iwslt/de-en/IWSLT16.TEDX.tst2013.de-en.en.xml\n",
      ".data/iwslt/de-en/IWSLT16.TEDX.tst2014.de-en.de.xml\n",
      ".data/iwslt/de-en/IWSLT16.TEDX.tst2014.de-en.en.xml\n",
      ".data/iwslt/de-en/train.tags.de-en.de\n",
      ".data/iwslt/de-en/train.tags.de-en.en\n",
      "{'src': <torchtext.data.field.Field object at 0x1258962e8>, 'trg': <torchtext.data.field.Field object at 0x125896160>}\n",
      "119076\n",
      "{'src': ['David', 'Gallo', ':', 'Das', 'ist', 'Bill', 'Lange', '.', 'Ich', 'bin', 'Dave', 'Gallo', '.'], 'trg': ['David', 'Gallo', ':', 'This', 'is', 'Bill', 'Lange', '.', 'I', \"'m\", 'Dave', 'Gallo', '.']}\n"
     ]
    }
   ],
   "source": [
    "# for purposes of this hw, only gather sentences of max length 20\n",
    "MAX_LEN = 20\n",
    "train, val, test = datasets.IWSLT.splits(exts=('.de', '.en'), fields=(DE, EN), \n",
    "                                         filter_pred=lambda x: len(vars(x)['src']) <= MAX_LEN and \n",
    "                                         len(vars(x)['trg']) <= MAX_LEN)\n",
    "print(train.fields)\n",
    "print(len(train))\n",
    "print(vars(train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('.', 113253), (',', 67237), ('ist', 24189), ('die', 23778), ('das', 17102), ('der', 15727), ('und', 15622), ('Sie', 15085), ('es', 13197), ('ich', 12946)]\n",
      "Size of German vocab 13353\n",
      "[('.', 113433), (',', 59512), ('the', 46029), ('to', 29177), ('a', 27548), ('of', 26794), ('I', 24887), ('is', 21775), (\"'s\", 20630), ('that', 19814)]\n",
      "Size of English vocab 11560\n",
      "2 3\n"
     ]
    }
   ],
   "source": [
    "# replace tokens that occur less than 5 times with unk tokens, take rest as our vocabulary\n",
    "MIN_FREQ = 5\n",
    "DE.build_vocab(train.src, min_freq=MIN_FREQ)\n",
    "EN.build_vocab(train.trg, min_freq=MIN_FREQ)\n",
    "print(DE.vocab.freqs.most_common(10))\n",
    "print(\"Size of German vocab\", len(DE.vocab))\n",
    "print(EN.vocab.freqs.most_common(10))\n",
    "print(\"Size of English vocab\", len(EN.vocab))\n",
    "print(EN.vocab.stoi[\"<s>\"], EN.vocab.stoi[\"</s>\"]) #vocab index for <s>, </s>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make our batch and val iterators\n",
    "BATCH_SIZE = 32\n",
    "train_iter, val_iter = data.BucketIterator.splits((train, val), batch_size=BATCH_SIZE, device=-1,\n",
    "                                                  repeat=False, sort_key=lambda x: len(x.src))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source\n",
      "Variable containing:\n",
      "\n",
      "Columns 0 to 10 \n",
      "    99   4715   1104    150     39     77      0     26     87      9      0\n",
      "    22    635    123   8758   4142    272    707      4     21    278      0\n",
      "  5912      5      0   1279    657     10     24     18     74    156    249\n",
      "    80   6403      4      0     24      3      0     41      3      0    239\n",
      "   731    907      0     62     32   3119      0      0     27      0   1488\n",
      "  5383     18      3   3510     25     15    127     37     90     29     15\n",
      "     8      3     31      0      0     89      6      5    117     56      0\n",
      "    11    927   5934    294   5141      8      0    527   6207    286      3\n",
      "  8760    198   7186      3   2247      7    149     48      8   3235    167\n",
      "   174    178    101   2601      8   8966      0    308      0     68    144\n",
      "   537    170   7248     79     15   1307     14   5863     34      0   3532\n",
      "    34     34    972     84      0    858    507   3153      7      8     18\n",
      "   731   4353      0     57   5141     15    149   9318      0     21   2992\n",
      "     0    907     27  11059      0    229      0     17   5017   1367     54\n",
      "     2      2      2      2      2     16      2      2      2    244      2\n",
      "\n",
      "Columns 11 to 21 \n",
      "   674     12      9     26     12    993   2151    218     12     39     12\n",
      "   331      5   3418     27     15   3911      9   1693     43  10649    202\n",
      "    68    286    346    100   1221    574     14     32    504    230      4\n",
      "     0      3      7      5   4458     46     44     57      8   9609     10\n",
      "    54      5      0    745     24    360  10684      3    144    658      7\n",
      "    13    286    354    169    148      0      0   1702   8358    590      0\n",
      "    83    113   1727    121     63      0      3     21   3070      3   9407\n",
      "  2185    158      3      3      7     29    167      0      3     37      3\n",
      "   888      3    163     58      0  11420     11    276      6     13     14\n",
      "     3   4304      5    503     83   5178    205      2      4     46     56\n",
      "    90     51   4671     13   2172      3      0    150    380    101     13\n",
      "   979   5664   5598     21     68   2510   1223    651      5      7    108\n",
      "    54     25  10988     46   4476      0     59      0   1057  10187      0\n",
      "  6046    553     47     38    750   2893     16   3024   5151   2773    239\n",
      "     2      2      2      2      2      2     17      2      2      2      2\n",
      "\n",
      "Columns 22 to 31 \n",
      "     9    329    102    993    104     28     12     12   9235    133\n",
      "   502   3420     59      7      4    119      6      5     24   1373\n",
      "    29    240     32      0      0      3     35   1126     12     27\n",
      "   296      9      0      5     29     31     57   1091     21     58\n",
      "  1637   2057      8    137      0     10   3305     32     47     91\n",
      "    14    193    225    285      3   6034      3     15     32      6\n",
      "  6215    393     30   1287    106    696    167    201     29   2482\n",
      "   240    697    358     33     14      4    448      3    136      3\n",
      "     3      3      0      3     51      8     13     45      0     52\n",
      "     5   1808     74    788    462    210      0     13     55      6\n",
      "  1786   2358      3    175      0     10      8    107    130     42\n",
      "   572     81    136     19      0   6034    231      0     38     32\n",
      "   189     65    358    619    536    696    451   1215   4469   1894\n",
      "   171      0      0    211   6011      4    234  11132   6317    135\n",
      "     2     16      2      2      2      2      2      2      2      2\n",
      "[torch.LongTensor of size 15x32]\n",
      "\n",
      "Target\n",
      "Variable containing:\n",
      "\n",
      "Columns 0 to 10 \n",
      "     2      2      2      2      2      2      2      2      2      2      2\n",
      "    48   1725   1142     14    511     24  10304     27   3501    214    956\n",
      "    47      6     20     98      6      5   1796     12     46    238     45\n",
      "   311    558   9567      8   4274     32     39     37      9      7    917\n",
      "  3054    908     15    473      5    125   3609     56     66      6   3359\n",
      "    59     26     95   2883     15     16   1313   2525      0   7078    269\n",
      "   155     30    364      5    392    191   3559     56     18   3610    460\n",
      "  2542   1383     13    139    272      7   5741      6     46   5294     86\n",
      "    18      5   6486    127     60     86     83    472      9     38      0\n",
      "    10     61   1868      0  11506    923   2403      9     66      6   1488\n",
      "   115    275   1167     59    451     35     71     42      0    132     17\n",
      "   217     25     25    136     18   3150      8   3301     28   2463    636\n",
      "    69     65    747    254   1027    399   6911   2307    661      9      7\n",
      "     7      7   1015    271   6457     29     13  10364      7      6     28\n",
      "   155   1276     38    169    780      6     12      4      6      0    956\n",
      "    18    908   4280      5      4    757      8      3   3140     18     45\n",
      "     8    189      0    638      3    363   3559      1   7317    149   1613\n",
      "   361      4      4     16      1     21   6281      1      4   5622   1271\n",
      "     4      3      3   1412      1      3      9      1      3     39      4\n",
      "     3      1      1      4      1      1    323      1      1      3      3\n",
      "     1      1      1      3      1      1      4      1      1      1      1\n",
      "     1      1      1      1      1      1      3      1      1      1      1\n",
      "\n",
      "Columns 11 to 21 \n",
      "     2      2      2      2      2      2      2      2      2      2      2\n",
      "   511     14     27     27     14     24    154     52     14     42     14\n",
      "     6      6   1741     12    604    258     35    138    113    598     10\n",
      "   265    132    307    245      5   2520   3194    225     16      9     74\n",
      "     9      9    272      6     20    453    121     71    288     82     16\n",
      "     6     64     17    164     11     94     20    162      7  10150    711\n",
      "     0      5      6    155     85     35   3596     16   1713     11    334\n",
      "     5      6   2043    100      6   3487     61     12     18     85     17\n",
      "    19    132   2465      5      0    260     10    152    104     15      6\n",
      "    43    114      5     61      0   1091     36      8   6334    778   9610\n",
      "   581      9    130    165    110     38   1042      0      5     49   3446\n",
      "     8     64     44     12    133   2582     82      0     20      6     13\n",
      "  1989      5     12   1641     51   5117   3137      4   1102   6370     19\n",
      "     7     11    103     13    113      5   1409    175     11      4    153\n",
      "  1925     35    249      4      6      8     21    131      6      3    126\n",
      "     5      8     29      3    415    893     22   3371    105      1      0\n",
      "    46   1550      6      1     11   2705      3    371    148      1      4\n",
      " 10902     17   8844      1   3315      4      1      4      9      1      3\n",
      "  1248    315      7      1      4      3      1      3   6474      1      1\n",
      "     4      4   4194      1      3      1      1      1      4      1      1\n",
      "     3      3      4      1      1      1      1      1      3      1      1\n",
      "     1      1      3      1      1      1      1      1      1      1      1\n",
      "\n",
      "Columns 22 to 31 \n",
      "     2      2      2      2      2      2      2      2      2      2\n",
      "    57    545     52   1222     24    457     14     14      0     24\n",
      "    79   2415     36      9     67     21     16    100     39     64\n",
      "     7     26   2937      6     12     34     23    102     14   4056\n",
      "   184     15     17   1167      0     62    836    692     31     25\n",
      "     7    736     18     13     38     13     18     56     26     73\n",
      "   104     49    156     28      0     16      0     19     73      6\n",
      "   535    660     72   1471      5     12      5    392    169    132\n",
      "    17    520      6    104     91   2008     18     71     49    100\n",
      "  5852      8   1703    685   4811   6550     16   1014      0      7\n",
      "   124    709    131     91    121      4   1224      6   1014    140\n",
      "    79      5   2832     86     58     34     94   3171   3377     33\n",
      "   661     40      5      8    727     62      7   3859     38      4\n",
      "   183     16     20    476      0    141    102      4     64      3\n",
      "     6    492    131      9   2294     16    158      3   8596      1\n",
      "   164      7   8849    685    785     12     18      1      4      1\n",
      "   371    492     45    136      4   2008    225      1      3      1\n",
      "     4     99      0      4      3   6550    160      1      1      1\n",
      "     3     33      4      3      1      4    522      1      1      1\n",
      "     1      0      3      1      1      3      4      1      1      1\n",
      "     1     21      1      1      1      1      3      1      1      1\n",
      "     1      3      1      1      1      1      1      1      1      1\n",
      "[torch.LongTensor of size 22x32]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# example of what a batch looks like\n",
    "batch = next(iter(train_iter))\n",
    "print(\"Source\")\n",
    "print(batch.src)\n",
    "print(\"Target\")\n",
    "print(batch.trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Als ich in meinen 20ern war , hatte ich meine erste Psychotherapie-Patientin .\r\n",
      "Ich war Doktorandin und studierte Klinische Psychologie in Berkeley .\r\n",
      "Sie war eine 26-jÃ¤hrige Frau namens Alex .\r\n",
      "Und als ich das hÃ¶rte , war ich erleichtert .\r\n",
      "Meine Kommilitonin bekam nÃ¤mlich einen Brandstifter als ersten Patienten .\r\n",
      "Und ich bekam eine Frau in den 20ern , die Ã¼ber Jungs reden wollte .\r\n",
      "Das kriege ich hin , dachte ich mir .\r\n",
      "Aber ich habe es nicht hingekriegt .\r\n",
      "Arbeit kam spÃ¤ter , Heiraten kam spÃ¤ter , Kinder kamen spÃ¤ter , selbst der Tod kam spÃ¤ter .\r\n",
      "Leute in den 20ern wie Alex und ich hatten nichts als Zeit .\r\n"
     ]
    }
   ],
   "source": [
    "\"\"\" our goal is to output predict the 100 most probable 3-gram that will begin \n",
    "    the target sentence. The submission format will be as follows, where each \n",
    "    word in the 3-gram will be separated by \"|\", and each 3-gram will be separated by space.\"\"\"\n",
    "!head ../data/source_test.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
